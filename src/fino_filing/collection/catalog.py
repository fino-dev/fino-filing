# collection/catalog.py
from __future__ import annotations

import json
from datetime import datetime
from typing import TYPE_CHECKING, Any

import duckdb

if TYPE_CHECKING:
    from .expr import Expr
    from .filing import Filing


class Catalog:
    """
    Catalogï¼ˆè§£é‡ˆã—ãªã„æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼‰

    è²¬å‹™:
        - ä¿å­˜
        - ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        - Indexç®¡ç†

    ðŸš¨ é‡è¦: ãƒ¢ãƒ‡ãƒ«ã‚’è§£é‡ˆã—ãªã„

    - ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ„å‘³ã‚’çŸ¥ã‚‰ãªã„
    - ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æŒãŸãªã„
    - Exprã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ã ã‘
    """

    def __init__(self, db_path: str):
        """
        Args:
            db_path: DuckDBãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.db_path = db_path
        self.conn = duckdb.connect(db_path)
        self._init_schema()

    def _init_schema(self):
        """
        ã‚¹ã‚­ãƒ¼ãƒžåˆæœŸåŒ–

        ç‰©ç†ã‚«ãƒ©ãƒ ã¯ Filing.get_indexed_fields() ã‹ã‚‰è‡ªå‹•æ±ºå®š
        """
        # åŸºæœ¬ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS filings (
                id VARCHAR PRIMARY KEY,
                source VARCHAR NOT NULL,
                checksum VARCHAR NOT NULL,
                name VARCHAR NOT NULL,
                is_zip BOOLEAN NOT NULL,
                created_at TIMESTAMP NOT NULL,
                path VARCHAR NOT NULL,
                data JSON NOT NULL
            )
        """)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_source ON filings(source)")
        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_created_at ON filings(created_at)"
        )
        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_checksum ON filings(checksum)"
        )

        self.conn.commit()

    def index(self, filing: Filing):
        """
        Filingç´¢å¼•

        Args:
            filing: ç´¢å¼•ã™ã‚‹Filing
        """
        data = filing.to_dict()

        # ç‰©ç†ã‚«ãƒ©ãƒ å€¤æŠ½å‡º
        indexed_fields = filing.get_indexed_fields()

        core_values = {
            "id": data.get("id"),
            "source": data.get("source"),
            "checksum": data.get("checksum"),
            "name": data.get("name"),
            "is_zip": data.get("is_zip", False),
            "created_at": data.get("created_at"),
            "path": data.get("path"),
        }

        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼
        for key in [
            "id",
            "source",
            "checksum",
            "name",
            "created_at",
            "path",
        ]:
            if core_values[key] is None:
                raise ValueError(f"Required field '{key}' is missing")

        # datetimeå¤‰æ›
        if isinstance(core_values["created_at"], str):
            core_values["created_at"] = datetime.fromisoformat(
                core_values["created_at"]
            )

        # JSONåŒ–
        json_data = json.dumps(data, ensure_ascii=False, default=str)

        # æŒ¿å…¥
        self.conn.execute(
            """
            INSERT OR REPLACE INTO filings 
            (id, source, checksum, name, is_zip, created_at, path, data)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """,
            [
                core_values["id"],
                core_values["source"],
                core_values["checksum"],
                core_values["name"],
                core_values["is_zip"],
                core_values["created_at"],
                core_values["path"],
                json_data,
            ],
        )

        self.conn.commit()

    def index_batch(self, filings: list[Filing]):
        """
        ãƒãƒƒãƒç´¢å¼•

        Args:
            filings: Filingä¸€è¦§
        """
        rows = []

        for filing in filings:
            data = filing.to_dict()

            core_values = {
                "id": data.get("id"),
                "source": data.get("source"),
                "checksum": data.get("checksum"),
                "name": data.get("name"),
                "is_zip": data.get("is_zip", False),
                "created_at": data.get("created_at"),
                "path": data.get("path"),
            }

            if isinstance(core_values["created_at"], str):
                core_values["created_at"] = datetime.fromisoformat(
                    core_values["created_at"]
                )

            json_data = json.dumps(data, ensure_ascii=False, default=str)

            rows.append(
                [
                    core_values["id"],
                    core_values["source"],
                    core_values["checksum"],
                    core_values["name"],
                    core_values["is_zip"],
                    core_values["created_at"],
                    core_values["path"],
                    json_data,
                ]
            )

        self.conn.executemany(
            """
            INSERT OR REPLACE INTO filings 
            (id, source, checksum, name, is_zip, created_at, path, data)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """,
            rows,
        )

        self.conn.commit()

    def get(self, id_: str) -> dict | None:
        """
        IDæŒ‡å®šå–å¾—

        Args:
            id_: Filing ID

        Returns:
            Filingè¾žæ›¸ or None
        """
        result = self.conn.execute(
            """
            SELECT data FROM filings WHERE id = ?
        """,
            [id_],
        ).fetchone()

        if not result:
            return None

        return json.loads(result[0])

    def search(
        self,
        expr: Expr | None = None,
        limit: int = 100,
        offset: int = 0,
        order_by: str = "created_at",
        desc: bool = True,
    ) -> list[dict]:
        """
        æ¤œç´¢ï¼ˆExpression APIï¼‰

        Args:
            expr: æ¤œç´¢æ¡ä»¶ï¼ˆExprã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
            limit: å–å¾—ä»¶æ•°ä¸Šé™
            offset: ã‚ªãƒ•ã‚»ãƒƒãƒˆ
            order_by: ã‚½ãƒ¼ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            desc: é™é †ãƒ•ãƒ©ã‚°

        Returns:
            Filingè¾žæ›¸ãƒªã‚¹ãƒˆ
        """
        sql = "SELECT data FROM filings"
        params = []

        # WHEREå¥
        if expr:
            sql += f" WHERE {expr.sql}"
            params = expr.params

        # ORDER BY
        order_direction = "DESC" if desc else "ASC"

        # ç‰©ç†ã‚«ãƒ©ãƒ ã‹åˆ¤å®š
        physical_columns = {
            "id",
            "source",
            "checksum",
            "name",
            "is_zip",
            "created_at",
            "path",
        }

        if order_by in physical_columns:
            sql += f" ORDER BY {order_by} {order_direction}"
        else:
            sql += f" ORDER BY json_extract(data, '$.{order_by}') {order_direction}"

        # LIMIT/OFFSET
        sql += f" LIMIT {limit} OFFSET {offset}"

        # å®Ÿè¡Œ
        rows = self.conn.execute(sql, params).fetchall()

        return [json.loads(row[0]) for row in rows]

    def search_raw(self, sql: str, params: list = None) -> list[Any]:
        """
        SQLç›´æŽ¥å®Ÿè¡Œï¼ˆé«˜åº¦ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ï¼‰

        Args:
            sql: SQLæ–‡
            params: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            çµæžœãƒªã‚¹ãƒˆ
        """
        if params is None:
            params = []

        return self.conn.execute(sql, params).fetchall()

    def count(self, expr: Expr | None = None) -> int:
        """
        ä»¶æ•°ã‚«ã‚¦ãƒ³ãƒˆ

        Args:
            expr: æ¤œç´¢æ¡ä»¶

        Returns:
            ä»¶æ•°
        """
        sql = "SELECT COUNT(*) FROM filings"
        params = []

        if expr:
            sql += f" WHERE {expr.sql}"
            params = expr.params

        result = self.conn.execute(sql, params).fetchone()
        return result[0] if result else 0

    def stats(self) -> dict:
        """
        çµ±è¨ˆæƒ…å ±

        Returns:
            çµ±è¨ˆè¾žæ›¸
        """
        result = self.conn.execute("""
            SELECT 
                COUNT(*) as total,
                COUNT(DISTINCT source) as sources,
                MIN(created_at) as earliest,
                MAX(created_at) as latest
            FROM filings
        """).fetchone()

        return {
            "total": result[0],
            "sources": result[1],
            "earliest": result[2],
            "latest": result[3],
        }

    def clear(self):
        """å…¨å‰Šé™¤"""
        self.conn.execute("DELETE FROM filings")
        self.conn.commit()

    def close(self):
        """æŽ¥ç¶šã‚¯ãƒ­ãƒ¼ã‚º"""
        self.conn.close()
